{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is for the major project submission for COMP7220/8220, on the language dataset and task. It contains the following sections:\n",
    "\n",
    "i. Importing the Data packages.\n",
    "\n",
    "ii. Data Preprocessing.\n",
    "\n",
    "iii. Conventional Machine Learning Approach.\n",
    "    \n",
    "    a. Logistic Regression Model.\n",
    "    \n",
    "    b. Linear SVM. \n",
    "\n",
    "iv. Deep Learning approach.\n",
    "\n",
    "    a. Long short-term memory Model.\n",
    "\n",
    "v. Public dataset.\n",
    "\n",
    "vi. Private dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING THE DATA PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from os.path import join \n",
    "import pickle\n",
    "import string\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer= PorterStemmer()\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded C:/Users/sadap/Downloads/ML proj\\text_word_to_idx.pkl..\n",
      "13978\n",
      "0 <NULL>\n",
      "1 <START>\n",
      "2 <END>\n",
      "3 it\n",
      "4 makes\n",
      "5 me\n",
      "6 so\n"
     ]
    }
   ],
   "source": [
    "def loading_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        file = pickle.load(f)\n",
    "        print ('Loaded %s..' %path)\n",
    "        return file\n",
    "\n",
    "dataset_path =('C:/Users/sadap/Downloads/ML proj')\n",
    "emotions = ['anger', 'fear', 'joy', 'sadness']\n",
    "\n",
    "trainingtweet = np.load(join(dataset_path, 'text_train_tweets.npy'))\n",
    "labeltraining = np.load(join(dataset_path, 'text_train_labels.npy'))\n",
    "vocab_list = loading_pickle(join(dataset_path, 'text_word_to_idx.pkl'))\n",
    "\n",
    "tweetvalue = np.load(join(dataset_path, 'text_val_tweets.npy'))\n",
    "labelvalue = np.load(join(dataset_path, 'text_val_labels.npy'))\n",
    "\n",
    "publictweets_test= np.load(join(dataset_path, 'text_test_public_tweets_rand.npy'))\n",
    "\n",
    "print(len(vocab_list))\n",
    "idx_to_word = {i: w for w, i in vocab_list.items()}\n",
    "for i in range(7):\n",
    "  print(i, idx_to_word[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringconversion(text):\n",
    "    string_list=[]\n",
    "    for arr in text:\n",
    "        string = \"\"\n",
    "        for i in arr:\n",
    "            if i>2: \n",
    "                string+= idx_to_word[i]\n",
    "                string+= \" \"\n",
    "        string_list.append(string)\n",
    "    return string_list\n",
    "\n",
    "trainingtweet=stringconversion(trainingtweet)\n",
    "tweetvalue=stringconversion(tweetvalue)\n",
    "trainingtweet=pd.DataFrame(trainingtweet)\n",
    "tweetvalue=pd.DataFrame(tweetvalue)\n",
    "\n",
    "\n",
    "labeltraining=pd.DataFrame(labeltraining)\n",
    "labelvalue=pd.DataFrame(labelvalue)\n",
    "\n",
    "\n",
    "labeltraining.rename(columns={0:'Emotion'},inplace=True)\n",
    "labelvalue.rename(columns={0:'Emotion'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_preprocessing(TXT):\n",
    "    TXT = TXT.astype(str)\n",
    "\n",
    "    TXT[0] = TXT[0].apply(lambda A: A.lower())\n",
    "    \n",
    "    TXT[0] = TXT[0].apply(lambda A: word_tokenize(A))\n",
    "\n",
    "    TXT = TXT.astype(str)\n",
    "    \n",
    "    TXT[0] = TXT[0].str.replace('[^\\w\\s]',' ')\n",
    "    \n",
    "\n",
    "    thamba = stopwords.words('english')\n",
    "    TXT[0] = TXT[0].apply(lambda A: \" \".join(A for A in A.split() if A not in thamba))\n",
    "\n",
    "\n",
    "    TXT[0] = TXT[0].apply(lambda A: lemma_conversion(A))\n",
    "\n",
    "\n",
    "    TOKEN_T = TXT[0].apply(lambda A: A.split())\n",
    "    ps = PorterStemmer()\n",
    "    TOKEN_T = TOKEN_T.apply(lambda A: [ps.stem(i) for i in A])\n",
    "\n",
    "    for i in range(len(TOKEN_T)):\n",
    "        TOKEN_T[i] = ' '.join(TOKEN_T[i])\n",
    "    TXT[0] = TOKEN_T\n",
    "    return TXT\n",
    "\n",
    "def lemma_conversion(sentence):\n",
    "    sent = TextBlob(sentence)\n",
    "    TL = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    W_T= [(w, TL.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
    "    LemA_list = [wd.lemmatize(tag) for wd, tag in W_T]\n",
    "    return \" \".join(LemA_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used Lemmatization to transform a word to it's root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingtweet=tweet_preprocessing(trainingtweet)\n",
    "tweetvalue=tweet_preprocessing(tweetvalue)\n",
    "Init_DF=np.r_[trainingtweet,tweetvalue]\n",
    "Init_DF=pd.DataFrame(Init_DF)\n",
    "up_DF=np.r_[labeltraining,labelvalue]\n",
    "up_DF=pd.DataFrame(up_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventional Machine Learning Approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data PreProcessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadap\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "Encoder = preprocessing.LabelEncoder()\n",
    "y = Encoder.fit_transform(up_DF.values)\n",
    "X_train, X_val, y_train, y_val = train_test_split(Init_DF[0].values, y, stratify=y, random_state=43, test_size=0.2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_C= CountVectorizer(analyzer='word')\n",
    "V_C.fit(X_train)\n",
    "X_vec =  V_C.transform(X_train)\n",
    "val_vec =  V_C.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Logistic Regression Model and Linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadap\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sadap\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 77.33644859813083\n",
      "LVSM accuracy: 80.19859813084112\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression Model\n",
    "\n",
    "L_R_Model = LogisticRegression(C=1)\n",
    "L_R_Model.fit(X_vec, y_train)\n",
    "y_pred = L_R_Model.predict(val_vec)\n",
    "LR_ac = (accuracy_score(y_pred, y_val)*100)\n",
    "\n",
    "#Linear SVM\n",
    "LSVM_MODEL = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n",
    "LSVM_MODEL.fit(X_vec, y_train)\n",
    "y_pred = LSVM_MODEL.predict(val_vec)\n",
    "LVSM_AC = (accuracy_score(y_pred, y_val)*100)\n",
    "\n",
    "print('Logistic Regression accuracy:', LR_ac)\n",
    "\n",
    "print('LVSM accuracy:', LVSM_AC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALYSIS\n",
    "\n",
    "In the conventional machine learning approach, LVSM model gives us the better accuracy as compared to linear regression model. As we can see that the LVSM Model acts better on the language data set provided on the kaggle. The prediction rate of the LVSM Model is 3% more than that of the other Conventional machine learning approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>omg mother daughter dull ni move dad worri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happi birthday user repeat miss excit back flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ever cri middl bomb rest someon wake emerg sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mental suffer worthless pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user courag driver shot bu show courag natur s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0         omg mother daughter dull ni move dad worri\n",
       "1  happi birthday user repeat miss excit back flo...\n",
       "2  ever cri middl bomb rest someon wake emerg sle...\n",
       "3                       mental suffer worthless pain\n",
       "4  user courag driver shot bu show courag natur s..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L =stringconversion(publictweets_test) \n",
    "STAR_DF=pd.DataFrame(L)\n",
    "STAR_DF=tweet_preprocessing(STAR_DF)\n",
    "STAR_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the string has been converted to word, i.e  tweets numbers- tweet words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction\n",
       "ID            \n",
       "1            3\n",
       "2            2\n",
       "3            1\n",
       "4            0\n",
       "5            1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTING_TWEETS= V_C.transform(STAR_DF[0])\n",
    "PREDICTING_TWEETS= LSVM_MODEL.predict(COUNTING_TWEETS)\n",
    "STAR_DF['Prediction']=pd.DataFrame(PREDICTING_TWEETS)\n",
    "STAR_DF.set_index(pd.Index(range(1,4065)),inplace=True)\n",
    "STAR_DF.index.name='ID'\n",
    "PT_csv=STAR_DF.drop(0,axis=1)\n",
    "PT_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT_csv.to_csv(r\"C:\\Users\\sadap\\Downloads\\ML proj\\45817901_conventional\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fukat_data=pd.read_csv(\"tweets_lab.csv\")\n",
    "fukat_data.rename(columns={'Tweet':0},inplace=True)\n",
    "fukat_tweetX=fukat_data[0]\n",
    "fukat_data.index.name='ID'\n",
    "fukat_tweetY=fukat_data['Emotion']\n",
    "fukat_tweetX=pd.DataFrame(fukat_tweetX)\n",
    "fukat_tweetY=pd.DataFrame(fukat_tweetY)\n",
    "fukat_tweetX=tweet_preprocessing(fukat_tweetX)\n",
    "fukat_tweetY=fukat_tweetY.replace({'anger':0,'fear':1,'joy':2,'sadness':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Emotion\n",
       "ID         \n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fukat_tweetY.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_DF=np.r_[Init_DF,fukat_tweetX]\n",
    "M_DF=pd.DataFrame(M_DF)\n",
    "sent_M_DF=np.r_[up_DF,fukat_tweetY]\n",
    "sent_M_DF=pd.DataFrame(sent_M_DF)\n",
    "sent_M_DF.rename(columns={0:'Emotion'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10958, 26) (10958, 4)\n",
      "(4697, 26) (4697, 4)\n"
     ]
    }
   ],
   "source": [
    "NEW_WORDS= 5000\n",
    "SEQ_LEN = 26\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=NEW_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(M_DF[0].values)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X = tokenizer.texts_to_sequences(M_DF[0].values)\n",
    "X = pad_sequences(X, maxlen= SEQ_LEN)\n",
    "Y = pd.get_dummies(sent_M_DF['Emotion']).values\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.3)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strings are converted to tokens, all the essential filters have been apllied such as the characters such as brackets,comma,etc has been removed and the upper cases word are converted to lower case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sadap\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9862 samples, validate on 1096 samples\n",
      "Epoch 1/10\n",
      "9862/9862 [==============================] - 8s 846us/step - loss: 1.0644 - accuracy: 0.5772 - val_loss: 0.5626 - val_accuracy: 0.8221\n",
      "Epoch 2/10\n",
      "9862/9862 [==============================] - 8s 769us/step - loss: 0.3969 - accuracy: 0.8745 - val_loss: 0.4445 - val_accuracy: 0.8513\n",
      "Epoch 3/10\n",
      "9862/9862 [==============================] - 7s 759us/step - loss: 0.2784 - accuracy: 0.9086 - val_loss: 0.4228 - val_accuracy: 0.8659\n",
      "Epoch 4/10\n",
      "9862/9862 [==============================] - 7s 746us/step - loss: 0.2413 - accuracy: 0.9197 - val_loss: 0.4391 - val_accuracy: 0.8604\n",
      "Epoch 5/10\n",
      "9862/9862 [==============================] - 7s 712us/step - loss: 0.2076 - accuracy: 0.9262 - val_loss: 0.4168 - val_accuracy: 0.8723\n",
      "Epoch 6/10\n",
      "9862/9862 [==============================] - 7s 729us/step - loss: 0.1908 - accuracy: 0.9280 - val_loss: 0.4319 - val_accuracy: 0.8686\n",
      "Epoch 7/10\n",
      "9862/9862 [==============================] - 7s 722us/step - loss: 0.1795 - accuracy: 0.9301 - val_loss: 0.4434 - val_accuracy: 0.8677\n",
      "Epoch 8/10\n",
      "9862/9862 [==============================] - 7s 712us/step - loss: 0.1691 - accuracy: 0.9333 - val_loss: 0.4381 - val_accuracy: 0.8558\n"
     ]
    }
   ],
   "source": [
    "DL_Model = Sequential()\n",
    "DL_Model.add(Embedding(NEW_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "DL_Model.add(SpatialDropout1D(0.2))\n",
    "DL_Model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "DL_Model.add(Dense(4, activation='softmax'))\n",
    "DL_Model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "history = DL_Model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Memory model is used which is a most efficient model in Deep Learning Approach, in this for string conversion \"ADAM\" optimizer is used, \"SOFTMAX\" activation function is used for multiple classes,here INPUT IS 100 and the output will be in the emotions category mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4697/4697 [==============================] - 1s 213us/step\n",
      "LSTM Accuracy : 0.8592718839645386\n"
     ]
    }
   ],
   "source": [
    "DL_Acc = DL_Model.evaluate(X_test,Y_test)\n",
    "print('LSTM Accuracy :',DL_Acc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>omg mother daughter dull ni move dad worri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happi birthday user repeat miss excit back flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ever cri middl bomb rest someon wake emerg sle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mental suffer worthless pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user courag driver shot bu show courag natur s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0         omg mother daughter dull ni move dad worri\n",
       "1  happi birthday user repeat miss excit back flo...\n",
       "2  ever cri middl bomb rest someon wake emerg sle...\n",
       "3                       mental suffer worthless pain\n",
       "4  user courag driver shot bu show courag natur s..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STAR_DF=pd.DataFrame(stringconversion(publictweets_test))\n",
    "STAR_DF=tweet_preprocessing(STAR_DF)\n",
    "STAR_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FL=[]\n",
    "for i in range(0,4064):\n",
    "    sequence = tokenizer.texts_to_sequences(STAR_DF.iloc[i])\n",
    "    padded = pad_sequences(sequence, maxlen=SEQ_LEN)\n",
    "    pred = DL_Model.predict(padded)\n",
    "    FL.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction\n",
       "ID            \n",
       "1            1\n",
       "2            2\n",
       "3            1\n",
       "4            3\n",
       "5            1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FL_DF=pd.DataFrame(FL)\n",
    "FL_DF.rename(columns={0:'Prediction'},inplace=True)\n",
    "FL_DF.set_index(pd.Index(range(1,4065)),inplace=True)\n",
    "FL_DF.index.name='ID'\n",
    "FL_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "FL_DF.to_csv(r\"C:\\Users\\sadap\\Downloads\\ML proj\\45817901_Deeplearning\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIVATE TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PVT = np.load(join(dataset_path, 'text_test_private_tweets.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PVT_test=pd.DataFrame(stringconversion(PVT))\n",
    "PVT_test=tweet_preprocessing(PVT_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "AKHRI_LIST=[]\n",
    "for i in range(len(PVT_test)):\n",
    "    t = tokenizer.texts_to_sequences(PVT_test.iloc[i])\n",
    "    v = pad_sequences(t, maxlen=SEQ_LEN)\n",
    "    pred = DL_Model.predict(v)\n",
    "    AKHRI_LIST.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FL_DF_NEW=pd.DataFrame(AKHRI_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FL_DF_NEW.rename(columns={0:'Prediction'},inplace=True)\n",
    "FL_DF_NEW.set_index(pd.Index(range(len(PVT_test))),inplace=True)\n",
    "FL_DF_NEW.index.name='ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prediction\n",
       "ID            \n",
       "0            2\n",
       "1            2\n",
       "2            1\n",
       "3            1\n",
       "4            1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FL_DF_NEW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FL_DF.to_csv(r\"C:\\Users\\sadap\\Downloads\\ML proj\\45817901_Deeplearning\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion.\n",
    "\n",
    "\n",
    "In the both approaches, performance is the key. The Deep Learning Approach does not work efficiently when there is samll data, but here the data is massive and the Conventional Machine Learning Approach is not efficient because the accuracy is less compared to the final LSTM model we have used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "\n",
    "1.https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17\n",
    "\n",
    "\n",
    "2.https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d\n",
    "\n",
    "\n",
    "3.https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "\n",
    "4.https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
